# TimeMixer算法分析

### 数据入口

1. **数据加载和预处理**  (data_loader.py)： 这个文件定义了多个数据集类，用于加载和处理时间序列数据。例如，Dataset_ETT_hour 和 Dataset_ETT_minute 类用于加载小时级和分钟级的时间序列数据。这些类处理数据的标准化、时间特征编码等。
2. **数据提供者** (data_factory.py)：根据传入的参数，这个文件负责实例化并返回适当的数据集和数据加载器。数据加载器 (DataLoader) 用于批量加载数据，并支持多线程加载。



### 数据处理

1. **序列分解** (series_decomp 在 TimeMixer.py 中)： TimeMixer模型使用序列分解技术来分离时间序列的趋势、季节性和残差部分。这有助于模型更好地学习时间序列的结构。
2. **多尺度处理** (MultiScaleSeasonMixing 和 MultiScaleTrendMixing 在 TimeMixer.py 中)： 模型采用多尺度混合策略来处理不同时间尺度上的季节性和趋势信息。
3. **Past Decomposable Mixing** (在 TimeMixer.py 中)： 这是一种编码器-解码器架构，用于处理过去的时间序列数据，并预测未来的值。
4. **模型架构** (Model 在 TimeMixer.py 中)： 核心，包括编码器、解码器以及它们之间的交互。模型利用上述的序列分解和多尺度处理技术来提高预测的准确性，生成预测输出。



### 数据处理结果出口

1. **预测输出** (forecast 在 TimeMixer.py 中) ： TimeMixer模型的输出是对未来时间序列的预测。在HVAC系统故障检测中，这可以是系统在未来某个时间点的状态预测。
2. **归一化和标准化** (Normalize 在 StandardNorm.py 中) ： 对数据进行归一化或标准化处理。
3. **异常检测**： 通过比较预测值和实际值，可以检测出系统是否可能出现故障。如果预测值与实际值显著不同，可能表明系统存在异常。
4. **逆变换** (inverse_transform 方法)： 如果数据在预处理阶段进行了标准化或其他变换，后处理阶段需要将预测结果转换回原始的数据尺度，以便于解释和实际应用。



# 数据入口--详解

data_loader.py 定义了多个数据集类，用于加载和处理不同类型的时间序列数据。

* **类 Dataset_ETT_hour**
  		用于加载小时级时间序列数据集，如 ETTm1 或 ETTh2 数据集。
  		处理数据的读取、标准化、时间特征编码，并将数据划分为训练集、验证集和测试集。
* **类 Dataset_ETT_minute**
  		类似于 Dataset_ETT_hour，但用于加载分钟级时间序列数据集。
* **类 Dataset_Custom**
  		允许用户自定义数据集的加载方式，提供了灵活性以适应不同的数据格式和需求。
* **类 Dataset_M4**
  		专门用于加载 M4 竞赛数据集，这是一个广泛用于时间序列预测的基准数据集。
* **类 PSMSegLoader**
  		加载和处理 PSM 数据集，这是一个用于时间序列预测的分段数据集。
* **类 MSLSegLoader**
  		加载和处理 MSL 数据集，同样是分段数据集，用于时间序列预测任务。
*  **类 SMAPSegLoader**
  		加载和处理 SMAP 数据集，这是一个遥感数据集，常用于时间序列预测。
* **类 SMDSegLoader**
  		加载和处理 SMD 数据集，这是一个多变量时间序列数据集。
* **类 SWATSegLoader**
  		加载和处理 SWAT 数据集，这是一个水文数据集，常用于时间序列预测。
* **类 UEAloader**
  		加载 UEA 时间序列分类归档库中的数据集，这是一个广泛用于时间序列分类任务的数据集集合。
* **类 Dataset_PEMS**
  		加载和处理 PEMS 数据集，这是一个交通数据集，常用于交通流量预测。
* **类 Dataset_Solar**
  		加载和处理太阳能辐射数据集，用于太阳能预测任务。



# 数据处理--详解

### 序列分解

将时间序列分解为趋势、季节性和随机成分。

##### 类 DFT_series_decomp

（TimeMixer.py 文件）实现了基于离散傅立叶变换（DFT）的序列分解方法。

```python
class DFT_series_decomp(nn.Module):
    def __init__(self, top_k=5):  # 参数top_k，表示保留的频率成分的数量
        super(DFT_series_decomp, self).__init__()
        self.top_k = top_k

	def forward(self, x):
        xf = torch.fft.rfft(x)  # 进行快速傅立叶变换
        freq = abs(xf)
        freq[0] = 0  # 将直流分量（频率为0）置零
        top_k_freq, top_list = torch.topk(freq, 5)  # 获取最大的k个频率成分
        xf[freq <= top_k_freq.min()] = 0  # 将非top_k的频率成分置零
        x_season = torch.fft.irfft(xf)  # 进行逆傅立叶变换，得到季节性成分
        x_trend = x - x_season  # 计算趋势成分
        return x_season, x_trend
```

1. `forward`方法首先对输入的时间序列`x`进行快速傅立叶变换（RFFT），得到其频域表示`xf`。
2. 然后取模得到频率的幅度，并将直流分量置零。
3. 使用`torch.topk`找出最大的`top_k`个频率成分，并将其保留，其余频率成分置零。
4. 对滤波后的频域进行逆傅立叶变换（IRFFT），得到对应的时域表示，即季节性成分`x_season`。
5. 从原始时间序列`x`中减去季节性成分，得到趋势成分`x_trend`。

##### 类 series_decomp

（Autoformer_EncDec.py 文件）实现了基于移动平均的序列分解方法。

```python
class series_decomp(nn.Module):
    def __init__(self, kernel_size):
        super(series_decomp, self).__init__()
        self.moving_avg = moving_avg(kernel_size, stride=1) # 趋势，时间序列的长期变化趋势。

    def forward(self, x):
        moving_mean = self.moving_avg(x)
        res = x - moving_mean # 残差，代表时间序列中除去趋势后的部分，可能包括季节性效应和随机噪声。
        return res, moving_mean
```



### 多尺度处理

处理不同时间尺度上的季节性和趋势信息。

##### 季节性模式混合

MultiScaleSeasonMixing（TimeMixer.py 文件）

```python
class MultiScaleSeasonMixing(nn.Module):
    def __init__(self, configs):
        super(MultiScaleSeasonMixing, self).__init__()
        # 创建一个由多个下采样层组成的列表，用于在不同时间尺度上混合季节性特征
        self.down_sampling_layers = torch.nn.ModuleList([
            nn.Sequential(  # 每个下采样层由一系列层组成
                torch.nn.Linear(  # 第一个线性层进行下采样
                    configs.seq_len // (configs.down_sampling_window ** i),  # 输入特征数量
                    configs.seq_len // (configs.down_sampling_window ** (i + 1)),  # 输出特征数量
                ),
                nn.GELU(),  # GELU激活函数
                torch.nn.Linear(  # 第二个线性层进行上采样
                    configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                    configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                ),
            )
            for i in range(configs.down_sampling_layers)  # 根据配置创建多个层
        ])

    # 用于混合不同时间尺度上的季节性特征
    def forward(self, season_list):
        # 初始化最高频和最低频的季节性特征
        out_high = season_list[0]
        out_low = season_list[1]
        out_season_list = [out_high.permute(0, 2, 1)] # 初始化输出季节性特征列表

        # 遍历季节性特征列表，进行多尺度混合
        for i in range(len(season_list) - 1):
            out_low_res = self.down_sampling_layers[i](out_high) # 使用下采样层处理高频率季节性特征
            out_low = out_low + out_low_res # 将处理后的特征与低频率季节性特征相加
            out_high = out_low # 更新高频率季节性特征为低频率季节性特征
            # 如果还有更多季节性特征，更新低频率季节性特征
            if i + 2 <= len(season_list) - 1:
                out_low = season_list[i + 2]
            out_season_list.append(out_high.permute(0, 2, 1)) # 将处理后的季节性特征添加到输出列表
        return out_season_list
```



##### 趋势模式混合

MultiScaleTrendMixing（TimeMixer.py 文件）

```python
class MultiScaleTrendMixing(nn.Module):
    def __init__(self, configs):
        super(MultiScaleTrendMixing, self).__init__()
        # 创建一个由多个上采样层组成的列表，用于在不同时间尺度上混合趋势特征
        self.up_sampling_layers = torch.nn.ModuleList([
            nn.Sequential(  # 每个上采样层由一系列层组成
                torch.nn.Linear(  # 第一个线性层进行上采样
                    configs.seq_len // (configs.down_sampling_window ** (i + 1)),
                    configs.seq_len // (configs.down_sampling_window ** i),
                ),
                nn.GELU(),  # GELU激活函数
                torch.nn.Linear(  # 第二个线性层进行下采样
                    configs.seq_len // (configs.down_sampling_window ** i),
                    configs.seq_len // (configs.down_sampling_window ** i),
                ),
            )
            # 反向遍历下采样层的数量，以便从最粗糙的尺度开始
            for i in reversed(range(configs.down_sampling_layers))
        ])

    # 前向传播函数，用于混合不同时间尺度上的趋势特征
    def forward(self, trend_list):
        # 复制并反转趋势特征列表，以便从最低频率开始处理
        trend_list_reverse = trend_list.copy()
        trend_list_reverse.reverse()
        # 初始化最低频率的趋势特征和最高频率的趋势特征
        out_low = trend_list_reverse[0]
        out_high = trend_list_reverse[1]
        # 初始化输出趋势特征列表
        out_trend_list = [out_low.permute(0, 2, 1)]

        # 遍历趋势特征列表，进行多尺度混合
        for i in range(len(trend_list_reverse) - 1):
            out_high_res = self.up_sampling_layers[i](out_low) # 使用上采样层处理低频率趋势特征
            out_high = out_high + out_high_res # 将处理后的特征与高频率趋势特征相加
            out_low = out_high # 更新低频率趋势特征为高频率趋势特征
            # 如果还有更多趋势特征，更新高频率趋势特征
            if i + 2 <= len(trend_list_reverse) - 1:
                out_high = trend_list_reverse[i + 2]
            out_trend_list.append(out_low.permute(0, 2, 1)) # 将处理后的趋势特征添加到输出列表
        out_trend_list.reverse() # 反转输出列表，以恢复原始的时间尺度顺序
        return out_trend_list
```



### Past Decomposable Mixing

编码器-解码器架构，用于处理过去的时间序列数据，并预测未来的值。

```python
class PastDecomposableMixing(nn.Module):
    def __init__(self, configs):
        super(PastDecomposableMixing, self).__init__()
        # 保存序列长度、预测长度和下采样窗口大小
        self.seq_len = configs.seq_len
        self.pred_len = configs.pred_len
        self.down_sampling_window = configs.down_sampling_window

        # 初始化层归一化和dropout层
        self.layer_norm = nn.LayerNorm(configs.d_model)
        self.dropout = nn.Dropout(configs.dropout)
        # 根据配置设置通道独立性
        self.channel_independence = configs.channel_independence

        # 根据配置选择序列分解方法
        if configs.decomp_method == 'moving_avg':
            self.decompsition = series_decomp(configs.moving_avg)
        elif configs.decomp_method == "dft_decomp":
            self.decompsition = DFT_series_decomp(configs.top_k)
        else:
            raise ValueError('decompsition is error')

        # 如果通道独立性为0，初始化跨层连接层
        if configs.channel_independence == 0:
            self.cross_layer = nn.Sequential(
                nn.Linear(in_features=configs.d_model, out_features=configs.d_ff), # 线性层
                nn.GELU(), # GELU激活函数
                nn.Linear(in_features=configs.d_ff, out_features=configs.d_model), # 线性层
            )

		# 初始化多尺度季节性混合和多尺度趋势混合模块
        self.mixing_multi_scale_season = MultiScaleSeasonMixing(configs)
        self.mixing_multi_scale_trend = MultiScaleTrendMixing(configs)

        # 初始化输出跨层连接层
        self.out_cross_layer = nn.Sequential(
            nn.Linear(in_features=configs.d_model, out_features=configs.d_ff),
            nn.GELU(),
            nn.Linear(in_features=configs.d_ff, out_features=configs.d_model),
        )

    # 用于执行Past Decomposable Mixing
    def forward(self, x_list):
        length_list = [] # 用于存储每个序列的长度
        for x in x_list:
            _, T, _ = x.size() # 获取序列的维度
            length_list.append(T)

        # 分解，获得季节和趋势
        season_list = []
        trend_list = []
        for x in x_list: # 对每个序列进行分解操作
            season, trend = self.decompsition(x)
            # 如果通道独立性为0，通过跨层连接层处理季节性和趋势成分
            if self.channel_independence == 0:
                season = self.cross_layer(season)
                trend = self.cross_layer(trend)
            # 将季节性和趋势成分添加到列表，并调整维度顺序
            season_list.append(season.permute(0, 2, 1))
            trend_list.append(trend.permute(0, 2, 1))

        # 调用多尺度处理模块
        out_season_list = self.mixing_multi_scale_season(season_list)
        out_trend_list = self.mixing_multi_scale_trend(trend_list)

        # 遍历原始序列和处理后的成分，进行重组和预测
        out_list = []
        for ori, out_season, out_trend, length in zip(x_list, out_season_list, out_trend_list,length_list):
            out = out_season + out_trend
            # 如果通道独立性为1，将处理后的序列与原始序列相加
            if self.channel_independence:
                out = ori + self.out_cross_layer(out)
            out_list.append(out[:, :length, :]) # 截断序列到原始长度，并将结果添加到输出列表
        return out_list
```



### 模型架构

类 Model（TimeMixer.py文件）。核心，生成预测输出。

```python
class Model(nn.Module):
    def __init__(self, configs):
        super(Model, self).__init__()
        self.configs = configs
        self.task_name = configs.task_name
        self.seq_len = configs.seq_len
        self.label_len = configs.label_len
        self.pred_len = configs.pred_len
        self.down_sampling_window = configs.down_sampling_window
        self.channel_independence = configs.channel_independence
        self.pdm_blocks = nn.ModuleList([PastDecomposableMixing(configs)
                                         for _ in range(configs.e_layers)])

        self.preprocess = series_decomp(configs.moving_avg)
        self.enc_in = configs.enc_in
        self.use_future_temporal_feature = configs.use_future_temporal_feature

        if self.channel_independence == 1:
            self.enc_embedding = DataEmbedding_wo_pos(1, configs.d_model, configs.embed, configs.freq,
                                                      configs.dropout)
        else:
            self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,
                                                      configs.dropout)

        self.layer = configs.e_layers
        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':
            self.predict_layers = torch.nn.ModuleList(
                [
                    torch.nn.Linear(
                        configs.seq_len // (configs.down_sampling_window ** i),
                        configs.pred_len,
                    )
                    for i in range(configs.down_sampling_layers + 1)
                ]
            )

            if self.channel_independence == 1:
                self.projection_layer = nn.Linear(
                    configs.d_model, 1, bias=True)
            else:
                self.projection_layer = nn.Linear(
                    configs.d_model, configs.c_out, bias=True)

                self.out_res_layers = torch.nn.ModuleList([
                    torch.nn.Linear(
                        configs.seq_len // (configs.down_sampling_window ** i),
                        configs.seq_len // (configs.down_sampling_window ** i),
                    )
                    for i in range(configs.down_sampling_layers + 1)
                ])

                self.regression_layers = torch.nn.ModuleList(
                    [
                        torch.nn.Linear(
                            configs.seq_len // (configs.down_sampling_window ** i),
                            configs.pred_len,
                        )
                        for i in range(configs.down_sampling_layers + 1)
                    ]
                )

            self.normalize_layers = torch.nn.ModuleList(
                [
                    Normalize(self.configs.enc_in, affine=True, non_norm=True if configs.use_norm == 0 else False)
                    for i in range(configs.down_sampling_layers + 1)
                ]
            )

    def out_projection(self, dec_out, i, out_res):
        dec_out = self.projection_layer(dec_out)
        out_res = out_res.permute(0, 2, 1)
        out_res = self.out_res_layers[i](out_res)
        out_res = self.regression_layers[i](out_res).permute(0, 2, 1)
        dec_out = dec_out + out_res
        return dec_out

    def pre_enc(self, x_list):
        if self.channel_independence == 1:
            return (x_list, None)
        else:
            out1_list = []
            out2_list = []
            for x in x_list:
                x_1, x_2 = self.preprocess(x)
                out1_list.append(x_1)
                out2_list.append(x_2)
            return (out1_list, out2_list)

    def __multi_scale_process_inputs(self, x_enc, x_mark_enc):
        if self.configs.down_sampling_method == 'max':
            down_pool = torch.nn.MaxPool1d(self.configs.down_sampling_window, return_indices=False)
        elif self.configs.down_sampling_method == 'avg':
            down_pool = torch.nn.AvgPool1d(self.configs.down_sampling_window)
        elif self.configs.down_sampling_method == 'conv':
            padding = 1 if torch.__version__ >= '1.5.0' else 2
            down_pool = nn.Conv1d(in_channels=self.configs.enc_in, out_channels=self.configs.enc_in,
                                  kernel_size=3, padding=padding,
                                  stride=self.configs.down_sampling_window,
                                  padding_mode='circular',
                                  bias=False)
        else:
            return x_enc, x_mark_enc
        # B,T,C -> B,C,T
        x_enc = x_enc.permute(0, 2, 1)

        x_enc_ori = x_enc
        x_mark_enc_mark_ori = x_mark_enc

        x_enc_sampling_list = []
        x_mark_sampling_list = []
        x_enc_sampling_list.append(x_enc.permute(0, 2, 1))
        x_mark_sampling_list.append(x_mark_enc)

        for i in range(self.configs.down_sampling_layers):
            x_enc_sampling = down_pool(x_enc_ori)

            x_enc_sampling_list.append(x_enc_sampling.permute(0, 2, 1))
            x_enc_ori = x_enc_sampling

            if x_mark_enc_mark_ori is not None:
                x_mark_sampling_list.append(x_mark_enc_mark_ori[:, ::self.configs.down_sampling_window, :])
                x_mark_enc_mark_ori = x_mark_enc_mark_ori[:, ::self.configs.down_sampling_window, :]

        x_enc = x_enc_sampling_list
        if x_mark_enc_mark_ori is not None:
            x_mark_enc = x_mark_sampling_list
        else:
            x_mark_enc = x_mark_enc

        return x_enc, x_mark_enc

    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):

        if self.use_future_temporal_feature:
            if self.channel_independence == 1:
                B, T, N = x_enc.size()
                x_mark_dec = x_mark_dec.repeat(N, 1, 1)
                self.x_mark_dec = self.enc_embedding(None, x_mark_dec)
            else:
                self.x_mark_dec = self.enc_embedding(None, x_mark_dec)

        x_enc, x_mark_enc = self.__multi_scale_process_inputs(x_enc, x_mark_enc)

        x_list = []
        x_mark_list = []
        if x_mark_enc is not None:
            for i, x, x_mark in zip(range(len(x_enc)), x_enc, x_mark_enc):
                B, T, N = x.size()
                x = self.normalize_layers[i](x, 'norm')
                if self.channel_independence == 1:
                    x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
                    x_mark = x_mark.repeat(N, 1, 1)
                x_list.append(x)
                x_mark_list.append(x_mark)
        else:
            for i, x in zip(range(len(x_enc)), x_enc, ):
                B, T, N = x.size()
                x = self.normalize_layers[i](x, 'norm')
                if self.channel_independence == 1:
                    x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
                x_list.append(x)

        # embedding
        enc_out_list = []
        x_list = self.pre_enc(x_list)
        if x_mark_enc is not None:
            for i, x, x_mark in zip(range(len(x_list[0])), x_list[0], x_mark_list):
                enc_out = self.enc_embedding(x, x_mark)  # [B,T,C]
                enc_out_list.append(enc_out)
        else:
            for i, x in zip(range(len(x_list[0])), x_list[0]):
                enc_out = self.enc_embedding(x, None)  # [B,T,C]
                enc_out_list.append(enc_out)

        # Past Decomposable Mixing as encoder for past
        for i in range(self.layer):
            enc_out_list = self.pdm_blocks[i](enc_out_list)

        # Future Multipredictor Mixing as decoder for future
        dec_out_list = self.future_multi_mixing(B, enc_out_list, x_list)

        dec_out = torch.stack(dec_out_list, dim=-1).sum(-1)
        dec_out = self.normalize_layers[0](dec_out, 'denorm')
        return dec_out

    def future_multi_mixing(self, B, enc_out_list, x_list):
        dec_out_list = []
        if self.channel_independence == 1:
            x_list = x_list[0]
            for i, enc_out in zip(range(len(x_list)), enc_out_list):
                dec_out = self.predict_layers[i](enc_out.permute(0, 2, 1)).permute(
                    0, 2, 1)  # align temporal dimension
                if self.use_future_temporal_feature:
                    dec_out = dec_out + self.x_mark_dec
                    dec_out = self.projection_layer(dec_out)
                else:
                    dec_out = self.projection_layer(dec_out)
                dec_out = dec_out.reshape(B, self.configs.c_out, self.pred_len).permute(0, 2, 1).contiguous()
                dec_out_list.append(dec_out)

        else:
            for i, enc_out, out_res in zip(range(len(x_list[0])), enc_out_list, x_list[1]):
                dec_out = self.predict_layers[i](enc_out.permute(0, 2, 1)).permute(
                    0, 2, 1)  # align temporal dimension
                dec_out = self.out_projection(dec_out, i, out_res)
                dec_out_list.append(dec_out)

        return dec_out_list

    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):
        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':
            dec_out_list = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
            return dec_out_list
        else:
            raise ValueError('Only forecast tasks implemented yet')
```

##### 初始化

```python
def __init__(self, configs):
    super(Model, self).__init__()
    self.configs = configs
    self.task_name = configs.task_name
    self.seq_len = configs.seq_len
    self.label_len = configs.label_len
    self.pred_len = configs.pred_len
    self.down_sampling_window = configs.down_sampling_window
    self.channel_independence = configs.channel_independence

    self.pdm_blocks = nn.ModuleList([PastDecomposableMixing(configs)
                                     for _ in range(configs.e_layers)]) # 初始化PDM模块列表
    self.preprocess = series_decomp(configs.moving_avg) # 调用序列分解
    self.enc_in = configs.enc_in # 编码器输入维度
    self.use_future_temporal_feature = configs.use_future_temporal_feature # 是否使用未来时间特征

    # 根据是否独立通道初始化编码器嵌入层
    if self.channel_independence == 1:
        self.enc_embedding = DataEmbedding_wo_pos(1, configs.d_model, configs.embed, configs.freq, configs.dropout)
    else:
        self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq, configs.dropout)

	self.layer = configs.e_layers # 编码器层数
        # 根据任务类型初始化预测层和回归层
    if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':
            # 初始化多尺度预测层
		self.predict_layers = torch.nn.ModuleList([
            torch.nn.Linear(
                configs.seq_len // (configs.down_sampling_window ** i),
                configs.pred_len,
            )
            for i in range(configs.down_sampling_layers + 1)
        ])

        # 如果是独立通道，初始化投影层到1维输出
        if self.channel_independence == 1:
            self.projection_layer = nn.Linear(configs.d_model, 1, bias=True)
        else:
            # 如果不是独立通道，初始化投影层到多维输出
            self.projection_layer = nn.Linear(configs.d_model, configs.c_out, bias=True)
            # 初始化输出残差层和回归层
            self.out_res_layers = torch.nn.ModuleList([
                torch.nn.Linear(
                    configs.seq_len // (configs.down_sampling_window ** i),
                    configs.seq_len // (configs.down_sampling_window ** i),
                )
                for i in range(configs.down_sampling_layers + 1)
            ])
            self.regression_layers = torch.nn.ModuleList([
                torch.nn.Linear(
                    configs.seq_len // (configs.down_sampling_window ** i),
                    configs.pred_len,
                )
                for i in range(configs.down_sampling_layers + 1)
            ])

		# 初始化归一化层
        self.normalize_layers = torch.nn.ModuleList([
            Normalize(self.configs.enc_in, affine=True, non_norm=True if configs.use_norm == 0 else False)
            for i in range(configs.down_sampling_layers + 1)
        ])
```



##### 多尺度输出投影

该方法用于将解码器的输出通过投影层转换为最终预测结果。如果模型配置为独立通道（`channel_independence == 1`），则使用一维输出；否则，使用多维输出，并结合残差和回归层。

```python
def out_projection(self, dec_out, i, out_res):
    dec_out = self.projection_layer(dec_out)
    out_res = out_res.permute(0, 2, 1)
    out_res = self.out_res_layers[i](out_res)
    out_res = self.regression_layers[i](out_res).permute(0, 2, 1)
    dec_out = dec_out + out_res
    return dec_out
```



##### 输入预处理

如果模型配置为独立通道，则直接返回序列；否则，返回分解后的趋势和季节性成分序列。

```python
def pre_enc(self, x_list):
    if self.channel_independence == 1:
        return (x_list, None)
    else:
        out1_list = []
        out2_list = []
        for x in x_list:
            x_1, x_2 = self.preprocess(x)
            out1_list.append(x_1)
            out2_list.append(x_2)
		return (out1_list, out2_list)
```



##### 多尺度处理输入数据

调整输入数据的尺度。

```python
def __multi_scale_process_inputs(self, x_enc, x_mark_enc):
    # 根据下采样方法选择适当的层
    if self.configs.down_sampling_method == 'max':
        down_pool = torch.nn.MaxPool1d(self.configs.down_sampling_window, return_indices=False)
    elif self.configs.down_sampling_method == 'avg':
        down_pool = torch.nn.AvgPool1d(self.configs.down_sampling_window)
    elif self.configs.down_sampling_method == 'conv':
        # 卷积下采样
        padding = 1 if torch.__version__ >= '1.5.0' else 2
        down_pool = nn.Conv1d(in_channels=self.configs.enc_in,
                              out_channels=self.configs.enc_in,
                              kernel_size=3, padding=padding,
                              stride=self.configs.down_sampling_window,
                              padding_mode='circular',
                              bias=False)
    else:
        return x_enc, x_mark_enc

    x_enc = x_enc.permute(0, 2, 1) # 转换维度以适应下采样操作
    x_enc_ori = x_enc
    x_mark_enc_mark_ori = x_mark_enc
    
    # 初始化采样后的编码器和时间标记数据列表
    x_enc_sampling_list = []
    x_mark_sampling_list = []
    x_enc_sampling_list.append(x_enc.permute(0, 2, 1))
    x_mark_sampling_list.append(x_mark_enc)

    # 执行多尺度下采样
    for i in range(self.configs.down_sampling_layers):
        x_enc_sampling = down_pool(x_enc_ori)

        x_enc_sampling_list.append(x_enc_sampling.permute(0, 2, 1))
        x_enc_ori = x_enc_sampling

        # 如果有时间标记数据，进行步长为down_sampling_window的下采样
        if x_mark_enc_mark_ori is not None:
            x_mark_sampling_list.append(x_mark_enc_mark_ori[:, ::self.configs.down_sampling_window, :])
            x_mark_enc_mark_ori = x_mark_enc_mark_ori[:, ::self.configs.down_sampling_window, :]

    x_enc = x_enc_sampling_list
    if x_mark_enc_mark_ori is not None:
    	x_mark_enc = x_mark_sampling_list
    else:
    	x_mark_enc = x_mark_enc

	return x_enc, x_mark_enc # 返回包含所有尺度的编码器输入数据和时间标记数据的列表
```



##### 预测

用于生成时间序列的预测。它首先处理输入数据，然后通过编码器和解码器生成预测结果。如果使用未来时间特征，还会将其与解码器输出结合。

```python
def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):
    if self.use_future_temporal_feature:
        # 使用未来时间特征
        if self.channel_independence == 1:
            B, T, N = x_enc.size()
            x_mark_dec = x_mark_dec.repeat(N, 1, 1)
            self.x_mark_dec = self.enc_embedding(None, x_mark_dec)
        else:
            self.x_mark_dec = self.enc_embedding(None, x_mark_dec)
	# 多尺度处理输入数据            
	x_enc, x_mark_enc = self.__multi_scale_process_inputs(x_enc, x_mark_enc)

    x_list = []
    x_mark_list = []
    if x_mark_enc is not None:
        for i, x, x_mark in zip(range(len(x_enc)), x_enc, x_mark_enc):
            B, T, N = x.size()
            x = self.normalize_layers[i](x, 'norm')
            if self.channel_independence == 1:
            x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
            x_mark = x_mark.repeat(N, 1, 1)
            x_list.append(x)
            x_mark_list.append(x_mark)
    else:
        for i, x in zip(range(len(x_enc)), x_enc, ):
            B, T, N = x.size()
            x = self.normalize_layers[i](x, 'norm')
            if self.channel_independence == 1:
            x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
            x_list.append(x)

	# embedding （编码器嵌入层）
    enc_out_list = []
    x_list = self.pre_enc(x_list) # 调用输入预处理
    if x_mark_enc is not None:
    	for i, x, x_mark in zip(range(len(x_list[0])), x_list[0], x_mark_list):
            enc_out = self.enc_embedding(x, x_mark)  # [B,T,C]
            enc_out_list.append(enc_out)
    else:
        for i, x in zip(range(len(x_list[0])), x_list[0]):
            enc_out = self.enc_embedding(x, None)  # [B,T,C]
            enc_out_list.append(enc_out)

    # 执行Past Decomposable Mixing作为编码器
    for i in range(self.layer):
        enc_out_list = self.pdm_blocks[i](enc_out_list)

    # 执行Future Multipredictor Mixing作为解码器
    dec_out_list = self.future_multi_mixing(B, enc_out_list, x_list)

    # 将解码器输出在时间维度上进行累加，并进行归一化处理
    dec_out = torch.stack(dec_out_list, dim=-1).sum(-1)
    dec_out = self.normalize_layers[0](dec_out, 'denorm')
    return dec_out
```



##### 未来多预测器混合

作为解码器的一部分，将编码器的输出与多尺度预测层结合，生成未来时间步的预测。对于独立通道和非独立通道，处理方式有所不同。

```python
# 多尺度未来多预测器混合函数
def future_multi_mixing(self, B, enc_out_list, x_list):
    dec_out_list = []
    if self.channel_independence == 1:
        x_list = x_list[0]
        for i, enc_out in zip(range(len(x_list)), enc_out_list):
            # 预测层
            dec_out = self.predict_layers[i](enc_out.permute(0, 2, 1)).permute(0, 2, 1)
            if self.use_future_temporal_feature:
                # 如果使用未来时间特征，将其加入到解码器输出
                dec_out = dec_out + self.x_mark_dec
                dec_out = self.projection_layer(dec_out)
            else:
                dec_out = self.projection_layer(dec_out)
            # 调整输出维度以匹配任务要求
            dec_out = dec_out.reshape(B, self.configs.c_out, self.pred_len).permute(0, 2, 1).contiguous()
            dec_out_list.append(dec_out)

    else:
        for i, enc_out, out_res in zip(range(len(x_list[0])), enc_out_list, x_list[1]):
            # 预测层
            dec_out = self.predict_layers[i](enc_out.permute(0, 2, 1)).permute(0, 2, 1)
            # 输出投影，包括残差和回归层
            dec_out = self.out_projection(dec_out, i, out_res)
            dec_out_list.append(dec_out)

    return dec_out_list
```



##### 前向传播

这是模型的入口方法，根据任务类型（长期预测或短期预测）调用`forecast`方法，并返回预测结果。如果模型配置为其他任务类型，将抛出异常。

```python
def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):
    if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':
        # 对长期预测或短期预测任务调用forecast函数
        dec_out_list = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
        return dec_out_list
    else:
        raise ValueError('Only forecast tasks implemented yet')
```

